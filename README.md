# Spark ETL Practice

## ðŸ“Œ Overview
This repository contains my hands-on practice using PySpark for data processing and ETL operations.  
It demonstrates core Spark concepts including transformations, joins, and scenario-based exercises.

## ðŸ›  Tech Stack
- Python
- PySpark
- Hadoop (Local Setup)

## ðŸš€ Topics Covered
- Reading data from files
- Data transformations
- Joins and aggregations
- Scenario-based Spark problems
- ETL-style processing logic

## ðŸŽ¯ Purpose
Built as part of my Data Engineering learning journey to strengthen Spark and big data processing skills.

## ðŸ“‚ Repository Structure
- `FileRead.py` â†’ File ingestion examples
- `Joins.py` â†’ Spark join operations
- `SparkPracticals.py` â†’ Spark transformation exercises
- `SparkScenarios.py` â†’ Scenario-based problems
- `DBConnect.py` â†’ Database connectivity practice
- `data/` â†’ Sample datasets

## âœ… Key Learnings
- Working with Spark DataFrames
- Applying transformations & actions
- Handling joins and filtering
- Understanding ETL workflow basics

---
âœ¨ This project is part of my continuous practice in Data Engineering & Spark.
